How can Facebook scalably model their billion-node social network?  How
can Twitter efficiently run a toipc model over billions of tweets?
``Big data'' today does not just mean more data to mine but also more things
to understand - more users, more documents, more images.
Modern machine learning and data mining faces the challenge of
scaling our classic models to both use all of the data available as well as build
larger and more complex models of our world. 
%In modern machine learning and data mining using models,
%which were designed for thousands of items, on billions of items is a constant
%challenge.  
%The big data revolution pushes our systems to not only be able to
%process moredata but also to be able to fit larger and more complex models.  
%Our ``documents'' in topic modeling tweets are shorter not longer and our
%social circles are not growing exponentially, but we have so many more of them
%requiring our models to scale with the data being produced.

In this paper we describe \method, a general framework for performing fast
machine learning on huge models and big data.  Our system uses a combination
of recent insights in stochastic learning theory to enable our
system innovations.  In particular, our system offers three contributions:
{\bf (1) Scalability:} Our system distributes both the data and model across
the cluster of machines, allowing the system to scale to terrabytes of data as
well as models with billions of parameters, beyond the size that can fit in
memory for each machine. {\bf (2) Versatility:} Our system supports
synchronized parameter updates, such as normalizing across the cluster.
As a result, we can fit a variety of machine learning models, including topic
models, dictionary learning, and mixed membership stochastic block models.
{\bf (3) Speed:} We use a \textcolor{red}{modification} of stochastic gradient
descent, called Always-On SGD, to continously improve our model fit, even if
there are slow workers that would otherwise obstruct model synchronization and
slow computation. 
Finally, we demonstrate that with our new approah, \method can fit ML models at
an unprecedented scale and faster than prior work.

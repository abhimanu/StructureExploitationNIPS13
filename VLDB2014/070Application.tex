We demonstrate that \method is a generic large scale machine learning system by
applying it over diverse set of real world problems that are non-trivial to
solve. We describe here a set of problems in machine learning from the sub-areas
of graphical models, natural language processing, computer vision and
computational social sciences. These applications are real world problems that
involve non-trivial complexity described in section~\ref{sec:complexQues}

\subsection{Latent dirichlet allocation (\lda)}
We described \lda in detail in section~\ref{sec:mdAbstract}. We further
elaborate on this model and its application here. The assumption that there
are a fixed set of topics and each document is composed of topics with certain
probabilistic weights is helpful in search engine queries and information
retrieval. The search engine can use topics as part of their indices to keep
similar documents together. This helps in retrieving faster and accurate results for
search queries~\cite{Wei:LDM}. A similar strtegy is used by libraries for
efficient storage of documents~\cite{Newman:ETM} in digital form. Besides prevalent in
text mining and natural language processing, it is one of the most common
building blocks of complex graphical models such as nested
chinese restaurant process~\cite{Blei:NCR} used in genetics for clustering
micro-array data~\cite{Qin:CMG}, hierarchical dirichlet process~\cite{hdp:2006} 
used for tracking trending topics~\cite{Gao:TCT}, among other things.

This model uses non-negativity, simplex as well as distributed simplex
constraints defined in section~\ref{sec:complexQues}. We will see in
section~\ref{sec:eval} as to how these constraints affect run time
and convergence quality.

\subsection{Dictionary learning (\dl)}
Dictionary Learning is a classical model in computer vision used for image
denoising, restoration~\cite{Mairal07sparserepresentation} and classification. 
 
\subsection{Mixed membership stochastic block models (\mmsb)}
\mmsb models 
